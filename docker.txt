==========================================================================
# DOCKER STORAGE
==========================================================================
docker volume create <volume_name>
docker volume create datavolume
docker volume ls
docker volume inspect datavolume

# Mounting a volume on Container
--------------------------------
docker container run -it --name container2 -v datavolume:/data alpine /bin/sh

# Inside the container, we can now create files in the /data folder
/ # cd /data
/ # echo "Some app code" > Code-01.txt
/ # echo "Some more code" > Code-02.txt

Now, Delete the Container with Volume mounted on it
docker container rm container2

Create a new Container and mount the Volume created in Step#1 on it
docker container run --name container4 -it --rm -v datavolume:/app/data \
centos:7 /bin/bash

cd /app/data
ls –l

# As expected, we should see the two files create in step#2
Code-01.txt
Code-02.txt
-------------------------------------------------------
# Sharing Data between containers using Docker Volumes
-------------------------------------------------------
# Create a container and mount a volume on it | Default volume mode: R/W
docker container run -it --name ContainerWithRWVolume -v shared-data:/data .alpine /bin/sh

# Create a new file inside the container (on mounted volume)
/ echo "New file present in docker volume" > /data/test-file.txt

# Now, exit from the container by pressing Ctrl+D or exit

# Create another container, say ContainerWithROVolume and mount a volume in Read Only mode
docker container run -it --name ContainerWithROVolume -v shared-data:/app/data:ro ubuntu:22.04 /bin/bash

# Check in the container if you can see the file created in the ContainerWithRWVolume container
ls -l /app/data

# Now, try to create a new file on the mounted volume
/ echo "New file for read only volume" > /app/data/test-file-2.txt

# It will fail with the following message:
bash: /app/data/test-file-2.txt: Read-only file system

==========================================================================
# DOCKER NETWORKING
==========================================================================
USING BRIDGE NETWORKS - bridge
--------------------------------------------------------------------------
docker network ls
docker network inspect bridge
docker network create --driver bridge sample-net
docker network create --driver bridge --subnet "10.1.0.0/16" testnet
docker network inspect sample-net | grep Subnet
docker network rm sample-net
docker network prune --force
--------------------------------------------------------------------------

// Create a network without specifying network - for bridge n/w
docker container run --name c1 -it --rm alpine:latest /bin/sh
docker container inspect c1
docker container exec c1 /bin/sh
ip addr
ip addr show eth0 - we can also see what MAC address and what IP have been associated with this container network namespace by Docker.
ip route

docker container run --name c2 -d --rm alpine:latest ping 127.0.0.1
docker container inspect --format "{{.NetworkSettings.IPAddress}}" c2


# Now, let’s create two additional containers, c3 and c4, and attach them to sample-net, which we
created earlier. For this, we’ll use the --network parameter

docker container run --name c3 --rm -d \
--network sample-net \
alpine:latest ping 127.0.0.1

docker container run --name c4 --rm -d \
--network sample-net \
alpine:latest ping 127.0.0.1

docker network inspect sample-net

# whether the c3 and c4 containers can freely communicate with each other?
- To demonstrate that this is indeed the case, we can exec into the c3 container:

$ docker container exec -it c3 /bin/sh
/ # ping c4

Instead of the container name, here, we use c4’s IP address:
/ # ping 172.20.0.3

We should get this output:
PING c4 (172.20.0.3): 56 data bytes
64 bytes from 172.20.0.3: seq=0 ttl=64 time=3.092 ms
64 bytes from 172.20.0.3: seq=1 ttl=64 time=0.481 ms
--------------------------------------------------------------------------
docker network inspect bridge
--------------------------------------------------------------------------
1) Creating Networks
   - To create a new network, use the docker network create command. 
   - You can specify the driver to use, such as bridge or host, by setting the "-d" flag. 
   - By default bridge network will be created if you omit the flag.

docker network create app-network -d bridge

2) Connecting Containers to Networks
   - You can attach new containers to a network by setting the --network flag with your docker run command.

docker run -it --rm --name bincontainer --network app-network busybox:latest

3) Next, start another container, this time without the --network flag (will go in default bridge network):
docker run -it --rm --name container2 busybox:latest

4) Now try communicating between the two containers, using their names:
# get inside container1
/ # ping container2
ping: bad address 'container2'

- The containers aren’t in the same network, so they can’t directly communicate with each other.

5) Join container2 to the same network as container1

docker network connect app-network container2

- The containers now share a network, which allows them to discover each other:
# in container1
/ # ping container2
PING container2 (172.22.0.3): 56 data bytes
64 bytes from 172.22.0.3: seq=0 ttl=64 time=4.205 ms

----------------------------------------------------------------------------
# USING HOST NETWORKS
----------------------------------------------------------------------------
Example-01
-------------

- You can enable host networking for a container by connecting it to the built-in host network:

docker run -d --name nginx --network host nginx:latest

- NGINX listens on port 80 by default. 
- Because the container's using a host network, you can access your NGINX server on your host's localhost:80 outside the container, even though no ports have been explicitly specified.

- To test: curl localhost:80

Example-02
----------
# Run an Alpine container and attach it to the host network
$ docker container run --rm -it --network host alpine:latest /bin/sh
/ # ip addr show eth0

[can see that 192.168.65.3 is the IP address that the host has been assigned and
that the MAC address shown here also corresponds to that of the host.]

We can also inspect the routes:
/ # ip route

----------------------------------------------------------------------------
# USING NULL NETWORKS
----------------------------------------------------------------------------
$ docker container run --rm -it --network none alpine:latest /bin/sh

/ # ip addr show eth0
ip: can't find device 'eth0'

/ # ip route
This returns nothing.
----------------------------------------------------------------------------
REMOVING CONTAINERS FROM THE NETWORKS
----------------------------------------------------------------------------
docker network disconnect demo-network container2

----------------------------------------------------------------------------
MANAGING NETWORKS
----------------------------------------------------------------------------
- docker network ls
- docker network rm <network-name> - To delete a network, disconnect or stop all the Docker containers that are assciated with it.
- docker network prune - automatically delete all unused networks using the network prune

----------------------------------------------------------------------------
DISABLING NETWORKS - none
----------------------------------------------------------------------------
- When a container's networking is disabled, it will have no connectivity available – either to other containers, or your wider network. 
- Disable networking by attaching your container to the none network.
- This lets you easily sandbox unknown services.

docker run -it --rm --network none busybox:latest

============================================================================
CONFIGURING DOCKER
============================================================================

docker container run --rm -it alpine /bin/sh
/ # export

This should produce the following output:
export HOME='/root'
export HOSTNAME='91250b722bc3'
export PATH='/usr/local/sbin:/usr/local/bin:...'
export PWD='/'
export SHLVL='1'
export TERM='xterm'

# Defining environment variables for containers
------------------------------------------------

docker container run --rm -it --env LOG_DIR=/var/log/my-log alpine /bin/sh
/ # export | grep LOG_DIR

The output should be as follows: LOG_DIR='/var/log/my-log'

# Define multiple environment variable
- We just need to repeat the --env (or -e) parameter

docker container run --rm -it \
--env LOG_DIR=/var/log/my-log \
--env MAX_LOG_FILES=5 \
--env MAX_LOG_SIZE=1G \
alpine /bin/sh

/ # export | grep LOG

We will see the following:
export LOG_DIR='/var/log/my-log'
export MAX_LOG_FILES='5'
export MAX_LOG_SIZE='1G'

============================================================================
DOCKER IMAGES
============================================================================

# Flask App Dockerfile
# Which base image to use?
FROM python:3.11-alpine

# Add metadata for the image
LABEL maintainer="KBindesh"

# Set the working directory for your app
WORKDIR /app

# Copy the app source code to working directory
COPY . .

# Install the dependencies | Run the command while building the image
RUN pip install -r requirements.txt

# Mention the port on which app container will be listening
# EXPOSE 8080

# ENTRYPOINT ["python"]

# Command to run when container starts
CMD ["python", "src/app.py"]
-------------------------------------------------------------------
docker build -t image1 .
docker run -it --name container -p 4000:8080 image1

docker run --rm -it --name test alpine /bin/sh
apk add curl
curl http://172.17.0.2:8080

-----------------------------
- By default, the docker run command does not attach the standard input stream (STDIN) of the process within the container to the host terminal. 
- However, it does connect the standard output (STDOUT) and standard error (STDERR) streams. - In other words, we’ll only see the output being printed without a way to send any input to it.
- If the main process of the container is expecting input, running it without attaching the STDIN will cause it to exit immediately.


# Running a Process With Input Prompt Without Attaching STDIN

docker run ubuntu passwd root
New password: Password change has been aborted.
passwd: Authentication token manipulation error
passwd: password unchanged


In this case, we see that the command now waits for our input.

When we pass the -i option, the docker run command attaches the input device to the main process within the container. Specifically, the input device it takes is the input device to the docker run command. Note the term “input device” here because the input device is not necessarily the terminal.

------------------------------------------------------------------
# Attaching Output Pipe to STDIN

We can also attach the output pipe to the STDIN of the process within the Docker container. For instance, let’s pipe the output of the echo command to a cat process in the container:

$ echo "This is a piped input" | docker run -i ubuntu cat

-------------------------------------------------------------------
# Allocating the Pseudo-Terminal With the -t Option

- From the official documentation, Docker states that the -t option will “allocate a pseudo-TTY” to the process inside the container. 
- TTY stands for Teletype and can be interpreted as a device that offers basic input-output. 
- The reason it’s a pseudo-TTY is that there’s no physical teletype needed, and it’s emulated using a combination of display driver and keyboard driver.

- For the sake of this article, it’s sufficient to think of a pseudo-TTY as a terminal console we’re using for running commands and reading output in Linux.

------------------------------------------------------------------------
# Missing Functionality Without the -t Option

- Without passing the -t option to docker run for the interactive mode, not all of the terminal-specific functionality will be working.

For example, most programs that prompt the user for a password will turn off the echo of the input. This allows the password to be hidden from the console.

Let’s run the passwd command with the -i option and complete the prompt:
$ docker run -i ubuntu passwd root 
New password: thisisanewpassword 
Retype new password: thisisanewpassword 
passwd: password updated successfully

Under typical usage, we know that passwd‘s password prompt does not display our password input. The way passwd achieves this is by turning off the echo option of the terminal. Since we started this process without allocating a pseudo-TTY, the echo-off functionality of the terminal is not taking effect here.

--------------------------------------------------------------------------
# Enabling Complete Terminal Functionality Using the -t Option

To enable complete terminal functionality, including the echo-off option, we can pass the -t option along with -i:

$ docker run -i -t ubuntu passwd root
New password: 
Retype new password: 
passwd: password updated successfully


Now, the echo-off option on the passwd command is working correctly under the pseudo-TTY environment.


-----------------------------------------------------------------------------
#  “Input device is not a TTY” Error

If we specify -t and then attach an output pipe to the STDIN of the container’s process, the docker run command will complain that the “input device is not a TTY”. This is because when the -t option is present, docker run will check if the input device is a TTY-like device. When it sees the input device is a pipe file, it’ll exit with an error:

$ echo "this is a pipe input" | docker run -i -t ubuntu cat
the input device is not a TTY
$ echo $?
1

------------------------------------------------------------------------------
SUMMARY


- We’ve learned that the -i option of the docker run command attaches the STDIN of the container to the host process. 
- Then, we’ve also seen how the -t option enables complete terminal functionality such as echo-off for password masking. 
- Then, we also simulated the “input device is not a TTY” error by piping the pipe files and specifying the -t option.


=========================================
DOCKER COMPOSE
=========================================
# Example-01
----------------
services:
  db:
    image: postgres:alpine
    environment:
      - POSTGRES_USER=dockeruser
      - POSTGRES_PASSWORD=dockerpass
      - POSTGRES_DB=pets
    volumes:
      - pg-data:/var/lib/postgresql/data
      - ./db:/docker-entrypoint-initdb.d

  pgadmin:
    image: dpage/pgadmin4
    ports:
      - "5050:80"
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@acme.com
      PGADMIN_DEFAULT_PASSWORD: admin
    volumes:
      - pgadmin-data:/var/lib/pgadmin

volumes:
  pg-data:
  pgadmin-data:


- docker compose up
- navigate to http://
localhost:5050
- docker compose down -v


- docker compose build
- docker-compose -f docker-compose.dev.yml build
- docker compose up --scale web=3
- docker compose up -d --scale web=3

- docker login -u gnschenker -p <password>
- docker-compose -f docker-compose.dev.yml push


Example-02
--------------
services:
  rabbitmq:
    image: rabbitmq:3.13.2-management-alpine
    container_name: 'rabbitmq'
    restart: always
    environment:
      - "RABBITMQ_DEFAULT_USER=username"
      - "RABBITMQ_DEFAULT_PASS=password"
    ports:
      - 15672:15672
      - 5672:5672
    healthcheck:
      test: ["CMD", "rabbitmqctl", "status"]
      interval: 30s
      timeout: 10s
      retries: 5
    volumes:
      - ./rabbitmq_enabled_plugins:/etc/rabbitmq/enabled_plugins
    networks:
      - backend_services
  order-service:
    build: src/order-service
    container_name: 'order-service'
    restart: always
    ports:
      - 3000:3000
    healthcheck:
      test: ["CMD", "wget", "-O", "/dev/null", "-q", "http://order-service:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
    environment:
      - ORDER_QUEUE_HOSTNAME=rabbitmq
      - ORDER_QUEUE_PORT=5672
      - ORDER_QUEUE_USERNAME=username
      - ORDER_QUEUE_PASSWORD=password
      - ORDER_QUEUE_NAME=orders
      - ORDER_QUEUE_RECONNECT_LIMIT=3
    networks:
      - backend_services
    depends_on:
      rabbitmq:
        condition: service_healthy
  product-service:
    build: src/product-service
    container_name: 'product-service'
    restart: always
    ports:
      - 3002:3002
    healthcheck:
      test: ["CMD", "wget", "-O", "/dev/null", "-q", "http://product-service:3002/health"]
      interval: 30s
      timeout: 10s
      retries: 5
    environment:
      - AI_SERVICE_URL=http://ai-service:5001/
    networks:
      - backend_services
  store-front:
    build: src/store-front
    container_name: 'store-front'
    restart: always
    ports:
      - 8080:8080
    healthcheck:
      test: ["CMD", "wget", "-O", "/dev/null", "-q", "http://store-front:80/health"]
      interval: 30s
      timeout: 10s
      retries: 5
    environment:
      - VUE_APP_PRODUCT_SERVICE_URL=http://product-service:3002/
      - VUE_APP_ORDER_SERVICE_URL=http://order-service:3000/
    networks:
      - backend_services
    depends_on:
      - product-service
      - order-service
networks:
  backend_services:
    driver: bridge

-----------------------------------------
docker compose -f docker-compose-quickstart.yml up -d

docker images

docker ps

http://localhost:8080

docker compose down


